---
layout: section
---

# Blick nach vorn

---

## Multi-Modal wird lokal

<div class="grid grid-cols-2 gap-8">

<div>

### ğŸ‘€ **Vision Models**
- **LLaVA:** Bilder verstehen und beschreiben
- **MiniCPM-V:** Kompakt, fÃ¼r Consumer Hardware
- **Qwen-VL:** Multilinguale Vision

</div>

<div v-click>

### ğŸµ **Audio Integration**
- **Whisper:** Speech-to-Text lokal
- **Bark:** Text-to-Speech Generation
- **MusicGen:** Musik aus Text

</div>

</div>

<v-click>

<div class="mt-6 p-4 bg-gradient-to-r from-green-100 to-blue-100 rounded-lg color-black">
<strong>ğŸš€ Vision 2025:</strong> Ein lokales System fÃ¼r Text, Bild, Audio und Video
</div>

</v-click>

---

## Kleiner werdende Modelle

<div class="text-center">

```mermaid
graph TD
    A[GPT-4: 1.7T Parameter] --> B[LLaMA 70B: 70B Parameter]
    B --> C[Phi-3 Mini: 3.8B Parameter]
    C --> D[Phi-3.5 MoE: 16x3.8B Parameter]
    D --> E[Zukunft: 1B Parameter, GPT-4 QualitÃ¤t?]
    
    style A fill:#ff6b6b
    style B fill:#4ecdc4
    style C fill:#45b7d1
    style D fill:#96ceb4
    style E fill:#feca57
```

</div>

<v-click>

### ğŸ§  **Techniques**
- **Mixture of Experts (MoE):** Nur aktive Parameter nutzen
- **Knowledge Distillation:** GroÃŸe Modelle "unterrichten" kleine
- **Quantization:** 1-Bit Models (BitNet) kommen

</v-click>

<v-click>

<div class="mt-6 p-4 bg-yellow-100 rounded-lg text-center color-black">
<strong>Ziel:</strong> GPT-4-Level Performance auf Smartphone-Hardware
</div>

</v-click>

---

## Private RAG & Orchestrierung

<div class="grid grid-cols-2 gap-8">

<div>

### ğŸ“š **Lokale RAG-Systeme**
- **Embeddings:** all-MiniLM, BGE-M3
- **Vector DBs:** ChromaDB, Qdrant, Weaviate
- **Documents:** PDFs, Wikis, Code-Repos
- **Privacy:** Alles bleibt lokal

</div>

<div v-click>

### ğŸ”— **LangChain Lokal**
- **Agents:** Planning, Tools, Memory
- **Chains:** Multi-Step Workflows  
- **Tools:** Web Search, Calculators, APIs
- **No Cloud:** Komplett lokale Orchestrierung

</div>

</div>

<v-click>

<div class="mt-6">

**Beispiel Use Case:**
```
Analysiere meine E-Mails â†’ Finde relevante Dokumente â†’ 
Erstelle Zusammenfassung â†’ Generiere Antwort-Entwurf
```

</div>

</v-click>

---

## Hybrid-Ansatz: Das Beste aus beiden Welten

<div class="grid grid-cols-2 gap-8">

<div>

### ğŸ  **Lokal fÃ¼r:**
- **Sensitive Daten:** PasswÃ¶rter, VertrÃ¤ge, Medizin
- **Batch Processing:** Code-Generierung Ã¼ber Nacht
- **Development:** Coding-Assistenz, Refactoring
- **Offline:** Flugzeug, schlechte Verbindung

</div>

<div v-click>

### â˜ï¸ **Cloud fÃ¼r:**
- **Complex Reasoning:** Mathematik, komplexe Logik
- **Latest Knowledge:** Aktuelle Events, neue APIs
- **High Throughput:** Viele parallele Anfragen
- **Latest Models:** GPT-o1, Claude 3.5 Opus

</div>

</div>

<v-click>

<div class="mt-6 p-4 bg-purple-100 rounded-lg color-black">
<strong>ğŸ¯ Smart Routing:</strong>
<ul>
<li>Einfache Fragen â†’ Lokales 7B Modell</li>
<li>Code-Review â†’ Lokales Code-Model</li>
<li>Komplexe Analyse â†’ Cloud GPT-4</li>
<li>Sensitive Daten â†’ Immer lokal</li>
</ul>
</div>

</v-click>

---

## Fazit: Die Zukunft ist hybrid

<v-clicks>

ğŸ¯ **2025 Prediction:**
- Lokal: 80% aller Developer-Tasks
- Cloud: 20% fÃ¼r komplexeste Probleme

ğŸ“± **Hardware-Trends:**
- Apple M4 mit 32GB unified memory als Standard
- NVIDIA RTX 5090 mit 32GB VRAM
- Specialized AI-Chips (Google TPU, Apple Neural Engine)

ğŸŒ **Ecosystem:**
- Bessere Tools, einfachere Installation
- Enterprise-grade lokale LLM-Stacks
- Regulation treibt lokale LÃ¶sungen

ğŸ’¡ **Bottom Line:**
Local LLMs sind nicht mehr "Nice to have" â€“ sie werden zum Standard fÃ¼r datensensitive Anwendungen

</v-clicks>

---

## Resources & WeiterfÃ¼hrende Links

<div class="grid grid-cols-2 gap-8">

<div>

### ğŸ”— **Tools**
- [Ollama](https://ollama.ai/) - CLI fÃ¼r lokale LLMs
- [LM Studio](https://lmstudio.ai/) - GUI fÃ¼r Experimente
- [Continue](https://continue.dev/) - VSCode Integration
- [Aider](https://github.com/paul-gauthier/aider) - Terminal Coding

</div>

<div>

### ğŸ“š **Lernen**
- [Hugging Face Course](https://huggingface.co/course/) - Deep Learning Basics
- [r/LocalLLaMA](https://reddit.com/r/LocalLLaMA) - Community
- [Papers with Code](https://paperswithcode.com/) - Latest Research
- [TheBloke](https://huggingface.co/TheBloke) - Quantized Models

</div>

</div>

<div class="text-center mt-8">
<h2>ğŸ¤ Q&A Zeit!</h2>
<p class="text-gray-600">Fragen, Diskussion, Erfahrungsaustausch</p>
</div>